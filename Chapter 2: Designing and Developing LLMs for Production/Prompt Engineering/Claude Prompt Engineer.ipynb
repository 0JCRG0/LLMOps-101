{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mshumer/gpt-prompt-engineer/blob/main/claude_prompt_engineer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WljjH8K3s7kG"
      },
      "source": [
        "# claude-prompt-engineer\n",
        "By Matt Shumer (https://twitter.com/mattshumer_)\n",
        "\n",
        "Github repo: https://github.com/mshumer/gpt-prompt-engineer\n",
        "\n",
        "Generate an optimal prompt for a given task.\n",
        "\n",
        "To generate a prompt:\n",
        "1. In the first cell, add in your Anthropic key.\n",
        "2. If you want, adjust your settings in the `Adjust settings here` cell\n",
        "2. In the last cell, fill in the description of your task, the variables the system should account for.\n",
        "3. Run all the cells! The AI will generate a number of candidate prompts, and test them all to find the best one!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dQmMZdkG_RA5"
      },
      "outputs": [],
      "source": [
        "from prettytable import PrettyTable\n",
        "import time\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "import itertools\n",
        "import wandb\n",
        "from tenacity import retry, stop_after_attempt, wait_exponential\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "load_dotenv(\".env\")\n",
        "\n",
        "ANTHROPIC_API_KEY = os.environ.get(\"ANTHROPIC_API_KEY\")\n",
        "use_wandb = False # set to True if you want to use wandb to log your config and results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzDKqEFd5wI5"
      },
      "source": [
        "## Adjust settings here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nIklSQohlgel"
      },
      "outputs": [],
      "source": [
        "# K is a constant factor that determines how much ratings change\n",
        "K = 32\n",
        "\n",
        "CANDIDATE_MODEL = 'claude-3-opus-20240229'\n",
        "CANDIDATE_MODEL_TEMPERATURE = 0.9\n",
        "\n",
        "GENERATION_MODEL = 'claude-3-opus-20240229'\n",
        "GENERATION_MODEL_TEMPERATURE = 0.8\n",
        "GENERATION_MODEL_MAX_TOKENS = 800\n",
        "\n",
        "TEST_CASE_MODEL = 'claude-3-opus-20240229'\n",
        "TEST_CASE_MODEL_TEMPERATURE = .8\n",
        "\n",
        "NUMBER_OF_TEST_CASES = 8 # this determines how many test cases to generate... the higher, the more expensive, but the better the results will be\n",
        "\n",
        "N_RETRIES = 3  # number of times to retry a call to the ranking model if it fails\n",
        "RANKING_MODEL = 'claude-3-opus-20240229'\n",
        "RANKING_MODEL_TEMPERATURE = 0.5\n",
        "\n",
        "NUMBER_OF_PROMPTS = 5 # this determines how many candidate prompts to generate... the higher, the more expensive, but the better the results will be\n",
        "\n",
        "WANDB_PROJECT_NAME = \"claude-prompt-eng\" # used if use_wandb is True, Weights &| Biases project name\n",
        "WANDB_RUN_NAME = None # used if use_wandb is True, optionally set the Weights & Biases run name to identify this run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HyIsyixwlgel"
      },
      "outputs": [],
      "source": [
        "def start_wandb_run():\n",
        "  # start a new wandb run and log the config\n",
        "  wandb.init(\n",
        "    project=WANDB_PROJECT_NAME,\n",
        "    name=WANDB_RUN_NAME,\n",
        "    config={\n",
        "      \"K\": K,\n",
        "      \"candiate_model\": CANDIDATE_MODEL,\n",
        "      \"candidate_model_temperature\": CANDIDATE_MODEL_TEMPERATURE,\n",
        "      \"generation_model\": GENERATION_MODEL,\n",
        "      \"generation_model_temperature\": GENERATION_MODEL_TEMPERATURE,\n",
        "      \"generation_model_max_tokens\": GENERATION_MODEL_MAX_TOKENS,\n",
        "      \"n_retries\": N_RETRIES,\n",
        "      \"ranking_model\": RANKING_MODEL,\n",
        "      \"ranking_model_temperature\": RANKING_MODEL_TEMPERATURE,\n",
        "      \"number_of_prompts\": NUMBER_OF_PROMPTS\n",
        "      })\n",
        "\n",
        "  return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Zk_2Uut-lgel"
      },
      "outputs": [],
      "source": [
        "# Optional logging to Weights & Biases to reocrd the configs, prompts and results\n",
        "if use_wandb:\n",
        "  start_wandb_run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wXeqMQpzzosx"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import re\n",
        "\n",
        "def remove_first_line(test_string):\n",
        "    if test_string.startswith(\"Here\") and test_string.split(\"\\n\")[0].strip().endswith(\":\"):\n",
        "        return re.sub(r'^.*\\n', '', test_string, count=1)\n",
        "    return test_string\n",
        "\n",
        "def generate_candidate_prompts(description, input_variables, test_cases, number_of_prompts):\n",
        "    headers = {\n",
        "        \"x-api-key\": ANTHROPIC_API_KEY,\n",
        "        \"anthropic-version\": \"2023-06-01\",\n",
        "        \"content-type\": \"application/json\"\n",
        "    }\n",
        "\n",
        "    variable_descriptions = \"\\n\".join(f\"{var['variable']}: {var['description']}\" for var in input_variables)\n",
        "\n",
        "    data = {\n",
        "        \"model\": CANDIDATE_MODEL,\n",
        "        \"max_tokens\": 1500,\n",
        "        \"temperature\": CANDIDATE_MODEL_TEMPERATURE,\n",
        "        \"system\": f\"\"\"Your job is to generate system prompts for Claude 3, given a description of the use-case, some test cases/input variable examples that will help you understand what the prompt will need to be good at.\n",
        "The prompts you will be generating will be for freeform tasks, such as generating a landing page headline, an intro paragraph, solving a math problem, etc.\n",
        "In your generated prompt, you should describe how the AI should behave in plain English. Include what it will see, and what it's allowed to output.\n",
        "<most_important>Make sure to incorporate the provided input variable placeholders into the prompt, using placeholders like {{{{VARIABLE_NAME}}}} for each variable. Ensure you place placeholders inside four squiggly lines like {{{{VARIABLE_NAME}}}}. At inference time/test time, we will slot the variables into the prompt, like a template.</most_important>\n",
        "Be creative with prompts to get the best possible results. The AI knows it's an AI -- you don't need to tell it this.\n",
        "You will be graded based on the performance of your prompt... but don't cheat! You cannot include specifics about the test cases in your prompt. Any prompts with examples will be disqualified.\n",
        "Here are the input variables and their descriptions:\n",
        "{variable_descriptions}\n",
        "Most importantly, output NOTHING but the prompt (with the variables contained in it like {{{{VARIABLE_NAME}}}}). Do not include anything else in your message.\"\"\",\n",
        "        \"messages\": [\n",
        "            {\"role\": \"user\", \"content\": f\"Here are some test cases:`{test_cases}`\\n\\nHere is the description of the use-case: `{description.strip()}`\\n\\nRespond with your flexible system prompt, and nothing else. Be creative, and remember, the goal is not to complete the task, but write a prompt that will complete the task.\"},\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    prompts = []\n",
        "\n",
        "    for i in range(number_of_prompts):\n",
        "        response = requests.post(\"https://api.anthropic.com/v1/messages\", headers=headers, json=data)\n",
        "\n",
        "        message = response.json()\n",
        "\n",
        "        response_text = message['content'][0]['text']\n",
        "\n",
        "        prompts.append(remove_first_line(response_text))\n",
        "\n",
        "    return prompts\n",
        "\n",
        "def expected_score(r1, r2):\n",
        "    return 1 / (1 + 10**((r2 - r1) / 400))\n",
        "\n",
        "def update_elo(r1, r2, score1):\n",
        "    e1 = expected_score(r1, r2)\n",
        "    e2 = expected_score(r2, r1)\n",
        "    return r1 + K * (score1 - e1), r2 + K * ((1 - score1) - e2)\n",
        "\n",
        "# Get Score - retry up to N_RETRIES times, waiting exponentially between retries.\n",
        "@retry(stop=stop_after_attempt(N_RETRIES), wait=wait_exponential(multiplier=1, min=4, max=70))\n",
        "def get_score(description, test_case, pos1, pos2, input_variables, ranking_model_name, ranking_model_temperature):\n",
        "    headers = {\n",
        "        \"x-api-key\": ANTHROPIC_API_KEY,\n",
        "        \"anthropic-version\": \"2023-06-01\",\n",
        "        \"content-type\": \"application/json\"\n",
        "    }\n",
        "\n",
        "    variable_values = \"\\n\".join(f\"{var['variable']}: {test_case.get(var['variable'], '')}\" for var in input_variables)\n",
        "\n",
        "    data = {\n",
        "        \"model\": RANKING_MODEL,\n",
        "        \"max_tokens\": 1,\n",
        "        \"temperature\": ranking_model_temperature,\n",
        "        \"system\": f\"\"\"Your job is to rank the quality of two outputs generated by different prompts. The prompts are used to generate a response for a given task.\n",
        "You will be provided with the task description, input variable values, and two generations - one for each system prompt.\n",
        "Rank the generations in order of quality. If Generation A is better, respond with 'A'. If Generation B is better, respond with 'B'.\n",
        "Remember, to be considered 'better', a generation must not just be good, it must be noticeably superior to the other.\n",
        "Also, keep in mind that you are a very harsh critic. Only rank a generation as better if it truly impresses you more than the other.\n",
        "Respond with your ranking ('A' or 'B'), and nothing else. Be fair and unbiased in your judgement.\"\"\",\n",
        "        \"messages\": [\n",
        "            {\"role\": \"user\", \"content\": f\"\"\"Task: {description.strip()}\n",
        "Variables: {test_case['variables']}\n",
        "Generation A: {remove_first_line(pos1)}\n",
        "Generation B: {remove_first_line(pos2)}\"\"\"},\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    response = requests.post(\"https://api.anthropic.com/v1/messages\", headers=headers, json=data)\n",
        "\n",
        "    message = response.json()\n",
        "\n",
        "    score = message['content'][0]['text']\n",
        "\n",
        "    return score\n",
        "\n",
        "@retry(stop=stop_after_attempt(N_RETRIES), wait=wait_exponential(multiplier=1, min=4, max=70))\n",
        "def get_generation(prompt, test_case, input_variables):\n",
        "    headers = {\n",
        "        \"x-api-key\": ANTHROPIC_API_KEY,\n",
        "        \"anthropic-version\": \"2023-06-01\",\n",
        "        \"content-type\": \"application/json\"\n",
        "    }\n",
        "\n",
        "\n",
        "    # Replace variable placeholders in the prompt with their actual values from the test case\n",
        "    for var_dict in test_case['variables']:\n",
        "        for variable_name, variable_value in var_dict.items():\n",
        "            prompt = prompt.replace(f\"{{{{{variable_name}}}}}\", variable_value)\n",
        "\n",
        "    data = {\n",
        "        \"model\": GENERATION_MODEL,\n",
        "        \"max_tokens\": GENERATION_MODEL_MAX_TOKENS,\n",
        "        \"temperature\": GENERATION_MODEL_TEMPERATURE,\n",
        "        \"system\": 'Complete the task perfectly.',\n",
        "        \"messages\": [\n",
        "            {\"role\": \"user\", \"content\": prompt},\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    response = requests.post(\"https://api.anthropic.com/v1/messages\", headers=headers, json=data)\n",
        "\n",
        "    message = response.json()\n",
        "\n",
        "    generation = message['content'][0]['text']\n",
        "\n",
        "    return generation\n",
        "\n",
        "def test_candidate_prompts(test_cases, description, input_variables, prompts):\n",
        "    # Initialize each prompt with an ELO rating of 1200\n",
        "    prompt_ratings = {prompt: 1200 for prompt in prompts}\n",
        "\n",
        "    # Calculate total rounds for progress bar\n",
        "    total_rounds = len(test_cases) * len(prompts) * (len(prompts) - 1) // 2\n",
        "\n",
        "    # Initialize progress bar\n",
        "    pbar = tqdm(total=total_rounds, ncols=70)\n",
        "\n",
        "    # For each pair of prompts\n",
        "    for prompt1, prompt2 in itertools.combinations(prompts, 2):\n",
        "        # For each test case\n",
        "        for test_case in test_cases:\n",
        "            # Update progress bar\n",
        "            pbar.update()\n",
        "\n",
        "            # Generate outputs for each prompt\n",
        "            generation1 = get_generation(prompt1, test_case, input_variables)\n",
        "            generation2 = get_generation(prompt2, test_case, input_variables)\n",
        "\n",
        "            # Rank the outputs\n",
        "            score1 = get_score(description, test_case, generation1, generation2, input_variables, RANKING_MODEL, RANKING_MODEL_TEMPERATURE)\n",
        "            score2 = get_score(description, test_case, generation2, generation1, input_variables, RANKING_MODEL, RANKING_MODEL_TEMPERATURE)\n",
        "\n",
        "            # Convert scores to numeric values\n",
        "            score1 = 1 if score1 == 'A' else 0 if score1 == 'B' else 0.5\n",
        "            score2 = 1 if score2 == 'B' else 0 if score2 == 'A' else 0.5\n",
        "\n",
        "            # Average the scores\n",
        "            score = (score1 + score2) / 2\n",
        "\n",
        "            # Update ELO ratings\n",
        "            r1, r2 = prompt_ratings[prompt1], prompt_ratings[prompt2]\n",
        "            r1, r2 = update_elo(r1, r2, score)\n",
        "            prompt_ratings[prompt1], prompt_ratings[prompt2] = r1, r2\n",
        "\n",
        "            # Print the winner of this round\n",
        "            if score > 0.5:\n",
        "                print(f\"Winner: {prompt1}\")\n",
        "            elif score < 0.5:\n",
        "                print(f\"Winner: {prompt2}\")\n",
        "            else:\n",
        "                print(\"Draw\")\n",
        "\n",
        "    # Close progress bar\n",
        "    pbar.close()\n",
        "\n",
        "    return prompt_ratings\n",
        "\n",
        "def generate_optimal_prompt(description, input_variables, num_test_cases=10, number_of_prompts=10, use_wandb=False):\n",
        "    if use_wandb:\n",
        "        wandb_table = wandb.Table(columns=[\"Prompt\", \"Ranking\"] + [var[\"variable\"] for var in input_variables])\n",
        "        if wandb.run is None:\n",
        "            start_wandb_run()\n",
        "\n",
        "    test_cases = generate_test_cases(description, input_variables, num_test_cases)\n",
        "    prompts = generate_candidate_prompts(description, input_variables, test_cases, number_of_prompts)\n",
        "    print('Here are the possible prompts:', prompts)\n",
        "    prompt_ratings = test_candidate_prompts(test_cases, description, input_variables, prompts)\n",
        "\n",
        "    table = PrettyTable()\n",
        "    table.field_names = [\"Prompt\", \"Rating\"] + [var[\"variable\"] for var in input_variables]\n",
        "    for prompt, rating in sorted(prompt_ratings.items(), key=lambda item: item[1], reverse=True):\n",
        "        # Use the first test case as an example for displaying the input variables\n",
        "        example_test_case = test_cases[0]\n",
        "        table.add_row([prompt, rating] + [example_test_case.get(var[\"variable\"], \"\") for var in input_variables])\n",
        "        if use_wandb:\n",
        "            wandb_table.add_data(prompt, rating, *[example_test_case.get(var[\"variable\"], \"\") for var in input_variables])\n",
        "\n",
        "    if use_wandb:\n",
        "        wandb.log({\"prompt_ratings\": wandb_table})\n",
        "        wandb.finish()\n",
        "    print(table)\n",
        "\n",
        "def generate_test_cases(description, input_variables, num_test_cases):\n",
        "    headers = {\n",
        "        \"x-api-key\": ANTHROPIC_API_KEY,\n",
        "        \"anthropic-version\": \"2023-06-01\",\n",
        "        \"content-type\": \"application/json\"\n",
        "    }\n",
        "\n",
        "    variable_descriptions = \"\\n\".join(f\"{var['variable']}: {var['description']}\" for var in input_variables)\n",
        "\n",
        "    data = {\n",
        "        \"model\": CANDIDATE_MODEL,\n",
        "        \"max_tokens\": 1500,\n",
        "        \"temperature\": CANDIDATE_MODEL_TEMPERATURE,\n",
        "        \"system\": f\"\"\"You are an expert at generating test cases for evaluating AI-generated content.\n",
        "Your task is to generate a list of {num_test_cases} test case prompts based on the given description and input variables.\n",
        "Each test case should be a JSON object with a 'test_design' field containing the overall idea of this test case, and a list of additional JSONs for each input variable, called 'variables'.\n",
        "The test cases should be diverse, covering a range of topics and styles relevant to the description.\n",
        "Here are the input variables and their descriptions:\n",
        "{variable_descriptions}\n",
        "Return the test cases as a JSON list, with no other text or explanation.\"\"\",\n",
        "        \"messages\": [\n",
        "            {\"role\": \"user\", \"content\": f\"Description: {description.strip()}\\n\\nGenerate the test cases. Make sure they are really, really great and diverse:\"},\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    response = requests.post(\"https://api.anthropic.com/v1/messages\", headers=headers, json=data)\n",
        "    message = response.json()\n",
        "\n",
        "    response_text = message['content'][0]['text']\n",
        "\n",
        "    test_cases = json.loads(response_text)\n",
        "\n",
        "    print('Here are the test cases:', test_cases)\n",
        "\n",
        "    return test_cases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJSSKFfV_X9F"
      },
      "source": [
        "# In the cell below, fill in your description and input variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "vCZvLyDepxFP"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'## Example usage\\ndescription = \"Given a prompt, generate a personalized email response.\" # this style of description tends to work well\\n\\ninput_variables = [\\n    {\"variable\": \"SENDER_NAME\", \"description\": \"The name of the person who sent the email.\"},\\n    {\"variable\": \"RECIPIENT_NAME\", \"description\": \"The name of the person receiving the email.\"},\\n    {\"variable\": \"TOPIC\", \"description\": \"The main topic or subject of the email. One to two sentences.\"}\\n]'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"## Example usage\n",
        "description = \"Given a prompt, generate a personalized email response.\" # this style of description tends to work well\n",
        "\n",
        "input_variables = [\n",
        "    {\"variable\": \"SENDER_NAME\", \"description\": \"The name of the person who sent the email.\"},\n",
        "    {\"variable\": \"RECIPIENT_NAME\", \"description\": \"The name of the person receiving the email.\"},\n",
        "    {\"variable\": \"TOPIC\", \"description\": \"The main topic or subject of the email. One to two sentences.\"}\n",
        "]\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "description = \"\"\"\n",
        "\n",
        "Given a prompt, generate a list of JSON objects that classify a candidate's CV against multiple job descriptions. The purpose is to classify the CV's suitability for each job opening into one of five categories: Highly Suitable, Moderately Suitable, Potentially Suitable, Marginally Suitable, or Not Suitable. The classification is based on the candidate's years of experience and the match between their skills, qualifications, and the job requirements. To perform this task, you will receive a candidate's CV delimited by #### characters, along with job IDs delimited by <> characters and their corresponding job descriptions delimited by ---- characters. The output must be a JSON object containing the job ID, suitability category, and a brief explanation for each classification.\n",
        "\"\"\"\n",
        "\n",
        "input_variables = [\n",
        "    {\"variable\": \"id\", \"description\": \"A key name of each JSON object within the list, representing the unique identifier for each job opening, and it corresponds to the one delimited by <> characters\"},\n",
        "    {\"variable\": \"suitability\", \"description\": \"A key name of each JSON object within the list, representing one of five categories (Highly Suitable, Moderately Suitable, Potentially Suitable, Marginally Suitable, or Not Suitable) which determines the level of compatibility between a user's CV and a job description.\"},\n",
        "    {\"variable\": \"explanation\", \"description\": \"A key name of each JSON object within the list, representing a brief explaination behind the chosen suitability category.\"}\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4gxg9uf_vIlr"
      },
      "outputs": [],
      "source": [
        "if use_wandb:\n",
        "    wandb.config.update({\"description\": description,\n",
        "                         \"input_variables\": input_variables,\n",
        "                         \"num_test_cases\": NUMBER_OF_TEST_CASES,\n",
        "                         \"number_of_prompts\": NUMBER_OF_PROMPTS})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mo9B4x4R_YVl"
      },
      "source": [
        "## Run this cell to start the prompt engineering process!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "7rWjcL2hlgen"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Here are the test cases: [{'test_design': 'Basic test case with a single job opening and a well-matched candidate CV', 'variables': [{'id': '<job1>', 'suitability': 'Highly Suitable', 'explanation': 'The candidate has 5+ years of relevant experience and possesses all the required skills for the job.'}]}, {'test_design': 'Test case with multiple job openings and a candidate CV that matches some but not all requirements', 'variables': [{'id': '<job1>', 'suitability': 'Moderately Suitable', 'explanation': 'The candidate has relevant experience but lacks some of the preferred qualifications.'}, {'id': '<job2>', 'suitability': 'Potentially Suitable', 'explanation': \"The candidate's experience is in a related field, but they may need additional training to meet all requirements.\"}, {'id': '<job3>', 'suitability': 'Not Suitable', 'explanation': \"The candidate's experience and skills do not align with the job requirements.\"}]}, {'test_design': 'Test case with a candidate CV that has no relevant experience for the given job openings', 'variables': [{'id': '<job1>', 'suitability': 'Not Suitable', 'explanation': 'The candidate lacks relevant experience and skills for the position.'}, {'id': '<job2>', 'suitability': 'Not Suitable', 'explanation': \"The candidate's background does not match the job requirements.\"}]}, {'test_design': 'Test case with a candidate CV that exceeds the requirements for some job openings', 'variables': [{'id': '<job1>', 'suitability': 'Highly Suitable', 'explanation': 'The candidate has extensive relevant experience and all the required skills for the job.'}, {'id': '<job2>', 'suitability': 'Moderately Suitable', 'explanation': 'The candidate is overqualified for this position based on their experience and skills.'}]}, {'test_design': 'Test case with job openings in different industries and a candidate CV that matches one industry', 'variables': [{'id': '<job1>', 'suitability': 'Highly Suitable', 'explanation': \"The candidate's experience and skills align perfectly with the requirements for this marketing position.\"}, {'id': '<job2>', 'suitability': 'Not Suitable', 'explanation': 'The candidate lacks experience in the finance industry, which is essential for this role.'}, {'id': '<job3>', 'suitability': 'Marginally Suitable', 'explanation': 'While the candidate has some transferable skills, they lack direct experience in the healthcare field.'}]}, {'test_design': 'Test case with a candidate CV that meets the minimum requirements but lacks preferred qualifications', 'variables': [{'id': '<job1>', 'suitability': 'Potentially Suitable', 'explanation': 'The candidate meets the minimum requirements but lacks some of the preferred qualifications, such as proficiency in certain programming languages.'}]}, {'test_design': 'Test case with a candidate CV that has relevant experience but in a different industry', 'variables': [{'id': '<job1>', 'suitability': 'Moderately Suitable', 'explanation': 'The candidate has relevant skills and experience, but their background is in a different industry. They may require some industry-specific training.'}]}, {'test_design': 'Test case with a candidate CV that has a mix of suitable and unsuitable qualities for the given job openings', 'variables': [{'id': '<job1>', 'suitability': 'Marginally Suitable', 'explanation': 'The candidate has some relevant skills but lacks the required years of experience for the position.'}, {'id': '<job2>', 'suitability': 'Potentially Suitable', 'explanation': \"The candidate's experience is in a related field, and they possess most of the required qualifications. Additional training may be necessary.\"}, {'id': '<job3>', 'suitability': 'Highly Suitable', 'explanation': \"The candidate's skills, experience, and qualifications are an excellent match for this job opening.\"}]}]\n",
            "Here are the possible prompts: ['\\nYou are an AI assistant that classifies a candidate\\'s suitability for multiple job openings based on their CV. Your input will include:\\n- The candidate\\'s CV, delimited by #### characters \\n- One or more job IDs, each delimited by <> characters\\n- The corresponding job description for each job ID, delimited by ---- characters\\n\\nFor each job ID provided, analyze the candidate\\'s CV against the job description and requirements. Classify the candidate\\'s suitability into one of five categories:\\n- Highly Suitable \\n- Moderately Suitable\\n- Potentially Suitable\\n- Marginally Suitable\\n- Not Suitable\\n\\nIn addition to the classification, provide a brief explanation for why you chose that suitability level, considering factors like:\\n- The candidate\\'s years of relevant experience \\n- The match between the candidate\\'s skills and qualifications and the job requirements\\n- Any transferable skills from related industries\\n- Gaps in required or preferred qualifications\\n\\nGenerate your output as a list of JSON objects, with each object containing three keys:\\n- id: The job ID, corresponding to the ones delimited by <> characters. Include the <> characters.\\n- suitability: The classified suitability level\\n- explanation: The brief explanation for the classification\\n\\nExample input:\\n####\\nJohn Doe\\nSoftware Engineer\\n5+ years experience in full-stack web development\\nProficient in JavaScript, Python, React, Node.js\\nB.S. in Computer Science\\n####\\n<job1>\\n----\\nSenior Frontend Engineer\\n- 5+ years frontend development experience \\n- Expert in React, Redux, TypeScript\\n- Experience with unit testing\\n----\\n<job2> \\n----\\nData Scientist\\n- Advanced degree in quantitative field\\n- 3+ years experience in data analysis and modeling\\n- Proficiency in R, SQL, data visualization tools\\n----\\n\\nExample output:\\n[\\n  {\\n    \"id\": \"<job1>\",\\n    \"suitability\": \"Moderately Suitable\",\\n    \"explanation\": \"The candidate has 5+ years of relevant web development experience and proficiency in React, but lacks mentioned expertise in Redux or TypeScript.\"\\n  },\\n  {\\n    \"id\": \"<job2>\",\\n    \"suitability\": \"Not Suitable\",\\n    \"explanation\": \"The candidate lacks an advanced degree and experience in data science. Their skills are not transferable to this role.\"\\n  }\\n]', '\\nYou will be provided with a candidate\\'s CV delimited by #### characters, and a list of job openings, each with a unique job ID delimited by <> characters and a corresponding job description delimited by ---- characters. \\n\\nYour task is to evaluate the candidate\\'s suitability for each job opening based on their CV and the job requirements. Classify the CV into one of five suitability categories for each job:\\n\\nHighly Suitable: The candidate has relevant experience, skills, and qualifications that closely match or exceed the job requirements.\\nModerately Suitable: The candidate has relevant experience and skills but may lack some preferred qualifications or years of experience.\\nPotentially Suitable: The candidate\\'s experience is in a related field, and they meet most requirements but may need additional training.\\nMarginally Suitable: The candidate has some relevant skills but lacks essential qualifications or significant years of experience.\\nNot Suitable: The candidate\\'s experience, skills, and qualifications do not align with the job requirements.\\n\\nFor each job, provide a brief explanation justifying the chosen suitability category based on the candidate\\'s qualifications and the job requirements.\\n\\nOutput a JSON object containing a list of classifications, with each classification as a separate object in the list. Each object should include:\\n- id: The job ID, matching the one provided and delimited by <> characters\\n- suitability: The chosen suitability category \\n- explanation: A brief explanation for the classification\\n\\nThe JSON object should be in this format:\\n[\\n  {\\n    \"id\": \"{{JOB_ID}}\",\\n    \"suitability\": \"{{SUITABILITY_CATEGORY}}\",\\n    \"explanation\": \"{{EXPLANATION}}\"\\n  },\\n  ...\\n]\\n\\nRemember to evaluate the candidate\\'s CV against each job description independently. Focus on the relevance of the candidate\\'s experience, skills, and qualifications to the specific requirements of each job.', '\\n{{CV}}\\n\\nAnalyze the candidate\\'s CV above and compare it to the following job descriptions to determine the candidate\\'s suitability for each role:\\n\\n{{JOB_DESCRIPTIONS}}\\n\\nFor each job ID enclosed in <>, classify the candidate into one of five suitability categories: \\nHighly Suitable - The candidate has the ideal experience, skills and qualifications and is an excellent fit for the role\\nModerately Suitable - The candidate meets most of the requirements but may lack some preferred qualifications or industry experience  \\nPotentially Suitable - The candidate has related experience and skills but would likely need some additional training to perform the role\\nMarginally Suitable - The candidate meets some basic requirements but lacks key experience or skills needed for the role\\nNot Suitable - The candidate\\'s experience and qualifications do not align with the job requirements\\n\\nProvide your output as a list of JSON objects, with each object containing:\\n- id: the job ID enclosed in <>  \\n- suitability: one of the five suitability categories above\\n- explanation: a concise 1-2 sentence explanation justifying your suitability classification\\n\\nExample:\\n[\\n  {\\n    \"id\": \"<job1>\",\\n    \"suitability\": \"Highly Suitable\",\\n    \"explanation\": \"The candidate has 5+ years of relevant experience and possesses all the required skills for the job.\"\\n  },\\n  {\\n    \"id\": \"<job2>\",\\n    \"suitability\": \"Not Suitable\", \\n    \"explanation\": \"The candidate\\'s experience and skills do not align with the job requirements.\"\\n  }\\n]', '\\nYou are an AI system designed to classify a candidate\\'s CV against multiple job descriptions and determine their suitability for each position. Your task is to generate a JSON object for each job opening, containing the following keys:\\n\\n\"id\": The unique identifier for the job opening, delimited by <> characters in the input.\\n\"suitability\": One of five categories (Highly Suitable, Moderately Suitable, Potentially Suitable, Marginally Suitable, or Not Suitable) based on the candidate\\'s experience, skills, and qualifications compared to the job requirements.\\n\"explanation\": A brief justification for the chosen suitability category.\\n\\nThe input will consist of:\\n- The candidate\\'s CV, delimited by #### characters\\n- Job IDs and their corresponding job descriptions, with the IDs delimited by <> characters and the descriptions delimited by ---- characters\\n\\nTo determine the suitability category for each job, consider the following factors:\\n- The candidate\\'s years of relevant experience\\n- The match between the candidate\\'s skills, qualifications, and the job requirements\\n- The candidate\\'s industry background compared to the job\\'s industry\\n- Whether the candidate meets the minimum and preferred qualifications for the position\\n\\nYour output should be a JSON list containing an object for each job opening, with the keys \"id\", \"suitability\", and \"explanation\". The explanation should briefly justify the chosen suitability category based on the factors mentioned above.\\n\\nInput:\\n{{CV}}\\n{{JOB_DESCRIPTIONS}}\\n\\nOutput:\\n[\\n{{#each JOB_DESCRIPTIONS}}\\n  {\\n    \"id\": \"{{ID}}\",\\n    \"suitability\": \"{{SUITABILITY}}\",\\n    \"explanation\": \"{{EXPLANATION}}\"\\n  }{{#unless @last}},{{/unless}}\\n{{/each}}\\n]', '\\nYou are an AI assistant that classifies a candidate\\'s suitability for multiple job openings based on their CV. You will receive the following input:\\n- The candidate\\'s CV delimited by #### characters \\n- A list of job openings, where each job opening contains:\\n  - A job ID delimited by <> characters\\n  - The corresponding job description delimited by ---- characters\\n\\nYour task is to analyze the candidate\\'s CV against each provided job description and classify their suitability into one of five categories: \\n- Highly Suitable\\n- Moderately Suitable\\n- Potentially Suitable\\n- Marginally Suitable\\n- Not Suitable\\n\\nTo determine the suitability, consider factors such as:\\n- The candidate\\'s years of relevant experience \\n- The match between the candidate\\'s skills and qualifications and the job requirements\\n- The relevance of the candidate\\'s industry background to the job\\n\\nThe output should be a JSON array containing an object for each job opening. Each object should include three keys:\\n- id: The job ID, corresponding to the one delimited by <> characters \\n- suitability: The suitability category (Highly Suitable, Moderately Suitable, Potentially Suitable, Marginally Suitable, or Not Suitable)\\n- explanation: A brief explanation (1-2 sentences) of why you chose that suitability category\\n\\nExample output format:\\n[\\n  {\\n    \"id\": \"{{ID}}\",\\n    \"suitability\": \"{{SUITABILITY}}\",\\n    \"explanation\": \"{{EXPLANATION}}\"\\n  },\\n  ...\\n]\\n\\nAnalyze the CV thoroughly against each job description to provide an accurate suitability classification and insightful explanation. The explanation should highlight key factors from the CV and job description that influenced your categorization.']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  2%|▊                                 | 2/80 [00:27<18:03, 13.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Winner: \n",
            "You are an AI assistant that classifies a candidate's suitability for multiple job openings based on their CV. Your input will include:\n",
            "- The candidate's CV, delimited by #### characters \n",
            "- One or more job IDs, each delimited by <> characters\n",
            "- The corresponding job description for each job ID, delimited by ---- characters\n",
            "\n",
            "For each job ID provided, analyze the candidate's CV against the job description and requirements. Classify the candidate's suitability into one of five categories:\n",
            "- Highly Suitable \n",
            "- Moderately Suitable\n",
            "- Potentially Suitable\n",
            "- Marginally Suitable\n",
            "- Not Suitable\n",
            "\n",
            "In addition to the classification, provide a brief explanation for why you chose that suitability level, considering factors like:\n",
            "- The candidate's years of relevant experience \n",
            "- The match between the candidate's skills and qualifications and the job requirements\n",
            "- Any transferable skills from related industries\n",
            "- Gaps in required or preferred qualifications\n",
            "\n",
            "Generate your output as a list of JSON objects, with each object containing three keys:\n",
            "- id: The job ID, corresponding to the ones delimited by <> characters. Include the <> characters.\n",
            "- suitability: The classified suitability level\n",
            "- explanation: The brief explanation for the classification\n",
            "\n",
            "Example input:\n",
            "####\n",
            "John Doe\n",
            "Software Engineer\n",
            "5+ years experience in full-stack web development\n",
            "Proficient in JavaScript, Python, React, Node.js\n",
            "B.S. in Computer Science\n",
            "####\n",
            "<job1>\n",
            "----\n",
            "Senior Frontend Engineer\n",
            "- 5+ years frontend development experience \n",
            "- Expert in React, Redux, TypeScript\n",
            "- Experience with unit testing\n",
            "----\n",
            "<job2> \n",
            "----\n",
            "Data Scientist\n",
            "- Advanced degree in quantitative field\n",
            "- 3+ years experience in data analysis and modeling\n",
            "- Proficiency in R, SQL, data visualization tools\n",
            "----\n",
            "\n",
            "Example output:\n",
            "[\n",
            "  {\n",
            "    \"id\": \"<job1>\",\n",
            "    \"suitability\": \"Moderately Suitable\",\n",
            "    \"explanation\": \"The candidate has 5+ years of relevant web development experience and proficiency in React, but lacks mentioned expertise in Redux or TypeScript.\"\n",
            "  },\n",
            "  {\n",
            "    \"id\": \"<job2>\",\n",
            "    \"suitability\": \"Not Suitable\",\n",
            "    \"explanation\": \"The candidate lacks an advanced degree and experience in data science. Their skills are not transferable to this role.\"\n",
            "  }\n",
            "]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  4%|█▎                                | 3/80 [00:54<24:49, 19.34s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Winner: \n",
            "You are an AI assistant that classifies a candidate's suitability for multiple job openings based on their CV. Your input will include:\n",
            "- The candidate's CV, delimited by #### characters \n",
            "- One or more job IDs, each delimited by <> characters\n",
            "- The corresponding job description for each job ID, delimited by ---- characters\n",
            "\n",
            "For each job ID provided, analyze the candidate's CV against the job description and requirements. Classify the candidate's suitability into one of five categories:\n",
            "- Highly Suitable \n",
            "- Moderately Suitable\n",
            "- Potentially Suitable\n",
            "- Marginally Suitable\n",
            "- Not Suitable\n",
            "\n",
            "In addition to the classification, provide a brief explanation for why you chose that suitability level, considering factors like:\n",
            "- The candidate's years of relevant experience \n",
            "- The match between the candidate's skills and qualifications and the job requirements\n",
            "- Any transferable skills from related industries\n",
            "- Gaps in required or preferred qualifications\n",
            "\n",
            "Generate your output as a list of JSON objects, with each object containing three keys:\n",
            "- id: The job ID, corresponding to the ones delimited by <> characters. Include the <> characters.\n",
            "- suitability: The classified suitability level\n",
            "- explanation: The brief explanation for the classification\n",
            "\n",
            "Example input:\n",
            "####\n",
            "John Doe\n",
            "Software Engineer\n",
            "5+ years experience in full-stack web development\n",
            "Proficient in JavaScript, Python, React, Node.js\n",
            "B.S. in Computer Science\n",
            "####\n",
            "<job1>\n",
            "----\n",
            "Senior Frontend Engineer\n",
            "- 5+ years frontend development experience \n",
            "- Expert in React, Redux, TypeScript\n",
            "- Experience with unit testing\n",
            "----\n",
            "<job2> \n",
            "----\n",
            "Data Scientist\n",
            "- Advanced degree in quantitative field\n",
            "- 3+ years experience in data analysis and modeling\n",
            "- Proficiency in R, SQL, data visualization tools\n",
            "----\n",
            "\n",
            "Example output:\n",
            "[\n",
            "  {\n",
            "    \"id\": \"<job1>\",\n",
            "    \"suitability\": \"Moderately Suitable\",\n",
            "    \"explanation\": \"The candidate has 5+ years of relevant web development experience and proficiency in React, but lacks mentioned expertise in Redux or TypeScript.\"\n",
            "  },\n",
            "  {\n",
            "    \"id\": \"<job2>\",\n",
            "    \"suitability\": \"Not Suitable\",\n",
            "    \"explanation\": \"The candidate lacks an advanced degree and experience in data science. Their skills are not transferable to this role.\"\n",
            "  }\n",
            "]\n"
          ]
        },
        {
          "ename": "RetryError",
          "evalue": "RetryError[<Future at 0x10db12d20 state=finished raised KeyError>]",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "File \u001b[0;32m~/Dev/Python/LLMs/LLMOps/venv/lib/python3.12/site-packages/tenacity/__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 382\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[5], line 122\u001b[0m, in \u001b[0;36mget_generation\u001b[0;34m(prompt, test_case, input_variables)\u001b[0m\n\u001b[1;32m    120\u001b[0m message \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n\u001b[0;32m--> 122\u001b[0m generation \u001b[38;5;241m=\u001b[39m \u001b[43mmessage\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m generation\n",
            "\u001b[0;31mKeyError\u001b[0m: 'content'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRetryError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgenerate_optimal_prompt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_variables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNUMBER_OF_TEST_CASES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNUMBER_OF_PROMPTS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_wandb\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[5], line 185\u001b[0m, in \u001b[0;36mgenerate_optimal_prompt\u001b[0;34m(description, input_variables, num_test_cases, number_of_prompts, use_wandb)\u001b[0m\n\u001b[1;32m    183\u001b[0m prompts \u001b[38;5;241m=\u001b[39m generate_candidate_prompts(description, input_variables, test_cases, number_of_prompts)\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHere are the possible prompts:\u001b[39m\u001b[38;5;124m'\u001b[39m, prompts)\n\u001b[0;32m--> 185\u001b[0m prompt_ratings \u001b[38;5;241m=\u001b[39m \u001b[43mtest_candidate_prompts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_cases\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_variables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m table \u001b[38;5;241m=\u001b[39m PrettyTable()\n\u001b[1;32m    188\u001b[0m table\u001b[38;5;241m.\u001b[39mfield_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrompt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRating\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m [var[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvariable\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m input_variables]\n",
            "Cell \u001b[0;32mIn[5], line 145\u001b[0m, in \u001b[0;36mtest_candidate_prompts\u001b[0;34m(test_cases, description, input_variables, prompts)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;66;03m# Generate outputs for each prompt\u001b[39;00m\n\u001b[1;32m    144\u001b[0m generation1 \u001b[38;5;241m=\u001b[39m get_generation(prompt1, test_case, input_variables)\n\u001b[0;32m--> 145\u001b[0m generation2 \u001b[38;5;241m=\u001b[39m \u001b[43mget_generation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_case\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_variables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;66;03m# Rank the outputs\u001b[39;00m\n\u001b[1;32m    148\u001b[0m score1 \u001b[38;5;241m=\u001b[39m get_score(description, test_case, generation1, generation2, input_variables, RANKING_MODEL, RANKING_MODEL_TEMPERATURE)\n",
            "File \u001b[0;32m~/Dev/Python/LLMs/LLMOps/venv/lib/python3.12/site-packages/tenacity/__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_f\u001b[39m(\u001b[38;5;241m*\u001b[39margs: t\u001b[38;5;241m.\u001b[39mAny, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: t\u001b[38;5;241m.\u001b[39mAny) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mAny:\n\u001b[0;32m--> 289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Dev/Python/LLMs/LLMOps/venv/lib/python3.12/site-packages/tenacity/__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 379\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "File \u001b[0;32m~/Dev/Python/LLMs/LLMOps/venv/lib/python3.12/site-packages/tenacity/__init__.py:326\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreraise:\n\u001b[1;32m    325\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m retry_exc\u001b[38;5;241m.\u001b[39mreraise()\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfut\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexception\u001b[39;00m()\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwait:\n\u001b[1;32m    329\u001b[0m     sleep \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwait(retry_state)\n",
            "\u001b[0;31mRetryError\u001b[0m: RetryError[<Future at 0x10db12d20 state=finished raised KeyError>]"
          ]
        }
      ],
      "source": [
        "generate_optimal_prompt(description, input_variables, NUMBER_OF_TEST_CASES, NUMBER_OF_PROMPTS, use_wandb)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
