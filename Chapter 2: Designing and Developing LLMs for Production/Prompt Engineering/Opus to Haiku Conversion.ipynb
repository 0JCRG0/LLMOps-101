{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mshumer/gpt-prompt-engineer/blob/main/opus_to_haiku_conversion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WljjH8K3s7kG"
      },
      "source": [
        "# opus-to-haiku - part of the `gpt-prompt-engineer` repo\n",
        "\n",
        "This notebook gives you the ability to go from Claude Opus to Claude Haiku -- reducing costs massively while keeping quality high.\n",
        "\n",
        "By Matt Shumer (https://twitter.com/mattshumer_)\n",
        "\n",
        "Github repo: https://github.com/mshumer/gpt-prompt-engineer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQmMZdkG_RA5"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "load_dotenv(\".env\")\n",
        "\n",
        "ANTHROPIC_API_KEY = os.environ.get(\"ANTHROPIC_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "wXeqMQpzzosx"
      },
      "outputs": [],
      "source": [
        "#@title Run this to prep the main functions\n",
        "\n",
        "import json\n",
        "import re\n",
        "\n",
        "def generate_candidate_prompts(task, prompt_example, response_example):\n",
        "    headers = {\n",
        "        \"x-api-key\": ANTHROPIC_API_KEY,\n",
        "        \"anthropic-version\": \"2023-06-01\",\n",
        "        \"content-type\": \"application/json\"\n",
        "    }\n",
        "\n",
        "    data = {\n",
        "        \"model\": 'claude-3-opus-20240229',\n",
        "        \"max_tokens\": 4000,\n",
        "        \"temperature\": .5,\n",
        "        \"system\": \"\"\"<task>Given an example training sample, create seven additional samples for the same task that are even better. Each example should contain a <prompt> and a <response>.</task>\n",
        "\n",
        "<rules>\n",
        "1. Ensure the new examples are diverse and unique from one another.\n",
        "2. They should all be perfect. If you make a mistake, this system won't work.\n",
        "</rules>\n",
        "\n",
        "Respond in this format:\n",
        "<response_format>\n",
        "<example_one>\n",
        "<prompt>\n",
        "PUT_PROMPT_HERE\n",
        "</prompt>\n",
        "<response>\n",
        "PUT_RESPONSE_HERE\n",
        "</response>\n",
        "</example_one>\n",
        "\n",
        "<example_two>\n",
        "<prompt>\n",
        "PUT_PROMPT_HERE\n",
        "</prompt>\n",
        "<response>\n",
        "PUT_RESPONSE_HERE\n",
        "</response>\n",
        "</example_two>\n",
        "\n",
        "...\n",
        "</response_format>\"\"\",\n",
        "        \"messages\": [\n",
        "            {\"role\": \"user\", \"content\": f\"\"\"<training_task>{task}</training_task>\n",
        "\n",
        "<prompt_example>\n",
        "{prompt_example}\n",
        "</prompt_example>\n",
        "\n",
        "<response_example>\n",
        "{response_example}\n",
        "</response_example>\"\"\"},\n",
        "        ]\n",
        "    }\n",
        "\n",
        "\n",
        "    response = requests.post(\"https://api.anthropic.com/v1/messages\", headers=headers, json=data)\n",
        "\n",
        "    response_text = response.json()['content'][0]['text']\n",
        "\n",
        "    # Parse out the prompts and responses\n",
        "    prompts_and_responses = []\n",
        "    examples = re.findall(r'<example_\\w+>(.*?)</example_\\w+>', response_text, re.DOTALL)\n",
        "    for example in examples:\n",
        "        prompt = re.findall(r'<prompt>(.*?)</prompt>', example, re.DOTALL)[0].strip()\n",
        "        response = re.findall(r'<response>(.*?)</response>', example, re.DOTALL)[0].strip()\n",
        "        prompts_and_responses.append({'prompt': prompt, 'response': response})\n",
        "\n",
        "    return prompts_and_responses\n",
        "\n",
        "def generate_system_prompt(task, prompt_examples):\n",
        "    headers = {\n",
        "        \"x-api-key\": ANTHROPIC_API_KEY,\n",
        "        \"anthropic-version\": \"2023-06-01\",\n",
        "        \"content-type\": \"application/json\"\n",
        "    }\n",
        "\n",
        "    data = {\n",
        "        \"model\": 'claude-3-opus-20240229',\n",
        "        \"max_tokens\": 1000,\n",
        "        \"temperature\": .5,\n",
        "        \"system\": \"\"\"<your_role>Given a user-description of their <task> a set of prompt / response pairs (it'll be in JSON for easy reading) for the types of outputs we want to generate given inputs, write a fantastic system prompt that describes the task to be done perfectly.</your_role>\n",
        "\n",
        "<rules>\n",
        "1. Do this perfectly.\n",
        "2. Respond only with the system prompt, and nothing else. No other text will be allowed.\n",
        "</rules>\n",
        "\n",
        "Respond in this format:\n",
        "<system_prompt>\n",
        "WRITE_SYSTEM_PROMPT_HERE\n",
        "</system_prompt>\"\"\",\n",
        "        \"messages\": [\n",
        "            {\"role\": \"user\", \"content\": f\"\"\"<task>{task}</task>\n",
        "\n",
        "<prompt_response_examples>\n",
        "{str(prompt_examples)}\n",
        "</prompt_response_examples>\"\"\"},\n",
        "        ]\n",
        "    }\n",
        "\n",
        "\n",
        "    response = requests.post(\"https://api.anthropic.com/v1/messages\", headers=headers, json=data)\n",
        "\n",
        "    response_text = response.json()['content'][0]['text']\n",
        "\n",
        "    # Parse out the prompt\n",
        "    system_prompt = response_text.split('<system_prompt>')[1].split('</system_prompt>')[0].strip()\n",
        "\n",
        "    return system_prompt\n",
        "\n",
        "def test_haiku(generated_examples, prompt_example, system_prompt):\n",
        "    headers = {\n",
        "        \"x-api-key\": ANTHROPIC_API_KEY,\n",
        "        \"anthropic-version\": \"2023-06-01\",\n",
        "        \"content-type\": \"application/json\"\n",
        "    }\n",
        "\n",
        "    messages = []\n",
        "\n",
        "    for example in generated_examples:\n",
        "      messages.append({\"role\": \"user\", \"content\": example['prompt']})\n",
        "      messages.append({\"role\": \"assistant\", \"content\": example['response']})\n",
        "\n",
        "    messages.append({\"role\": \"user\", \"content\": prompt_example.strip()})\n",
        "\n",
        "    data = {\n",
        "        \"model\": 'claude-3-haiku-20240307',\n",
        "        \"max_tokens\": 2000,\n",
        "        \"temperature\": .5,\n",
        "        \"system\": system_prompt,\n",
        "        \"messages\": messages,\n",
        "    }\n",
        "\n",
        "\n",
        "    response = requests.post(\"https://api.anthropic.com/v1/messages\", headers=headers, json=data)\n",
        "\n",
        "    response_text = response.json()['content'][0]['text']\n",
        "\n",
        "    return response_text\n",
        "\n",
        "def run_haiku_conversion_process(task, prompt_example, response_example):\n",
        "\n",
        "    print('Generating the prompts / responses...')\n",
        "    # Generate candidate prompts\n",
        "    generated_examples = generate_candidate_prompts(task, prompt_example, response_example)\n",
        "\n",
        "    print('Prompts / responses generated. Now generating system prompt...')\n",
        "\n",
        "    # Generate the system prompt\n",
        "    system_prompt = generate_system_prompt(task, generated_examples)\n",
        "\n",
        "    print('System prompt generated:', system_prompt)\n",
        "\n",
        "\n",
        "    print('\\n\\nTesting the new prompt on Haiku, using your input example...')\n",
        "    # Test the generated examples and system prompt with the Haiku model\n",
        "    haiku_response = test_haiku(generated_examples, prompt_example, system_prompt)\n",
        "\n",
        "    print('Haiku responded with:')\n",
        "    print(haiku_response)\n",
        "\n",
        "    print('\\n\\n!! CHECK THE FILE DIRECTORY, THE PROMPT IS NOW SAVED THERE !!')\n",
        "\n",
        "    # Create a dictionary with all the relevant information\n",
        "    result = {\n",
        "        \"task\": task,\n",
        "        \"initial_prompt_example\": prompt_example,\n",
        "        \"initial_response_example\": response_example,\n",
        "        \"generated_examples\": generated_examples,\n",
        "        \"system_prompt\": system_prompt,\n",
        "        \"haiku_response\": haiku_response\n",
        "    }\n",
        "\n",
        "    # Save the Haiku prompt to a Python file\n",
        "    with open(\"haiku_prompt.py\", \"w\") as file:\n",
        "        file.write('system_prompt = \"\"\"' + system_prompt + '\"\"\"\\n\\n')\n",
        "\n",
        "        file.write('messages = [\\n')\n",
        "        for example in generated_examples:\n",
        "            file.write('    {\"role\": \"user\", \"content\": \"\"\"' + example['prompt'] + '\"\"\"},\\n')\n",
        "            file.write('    {\"role\": \"assistant\", \"content\": \"\"\"' + example['response'] + '\"\"\"},\\n')\n",
        "\n",
        "        file.write('    {\"role\": \"user\", \"content\": \"\"\"' + prompt_example.strip() + '\"\"\"}\\n')\n",
        "        file.write(']\\n')\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZujTAzhuBMea"
      },
      "source": [
        "## Fill in your task, prompt_example, and response_example here. Make sure you keep the quality really high here... this is the most important step!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSZqqOoQ-5_E"
      },
      "outputs": [],
      "source": [
        "task = \"refactoring complex code\"\n",
        "\n",
        "prompt_example = \"\"\"def calculate_total(prices, tax, discount, shipping_fee, gift_wrap_fee, membership_discount):\n",
        "\n",
        "    total = 0\n",
        "\n",
        "    for i in range(len(prices)):\n",
        "\n",
        "        total += prices[i]\n",
        "\n",
        "    if membership_discount != 0:\n",
        "\n",
        "        total = total - (total * (membership_discount / 100))\n",
        "\n",
        "    if discount != 0:\n",
        "\n",
        "        total = total - (total * (discount / 100))\n",
        "\n",
        "    total = total + (total * (tax / 100))\n",
        "\n",
        "    if total < 50:\n",
        "\n",
        "        total += shipping_fee\n",
        "\n",
        "    else:\n",
        "\n",
        "        total += shipping_fee / 2\n",
        "\n",
        "    if gift_wrap_fee != 0:\n",
        "\n",
        "        total += gift_wrap_fee * len(prices)\n",
        "\n",
        "    if total > 1000:\n",
        "\n",
        "        total -= 50\n",
        "\n",
        "    elif total > 500:\n",
        "\n",
        "        total -= 25\n",
        "\n",
        "    total = round(total, 2)\n",
        "\n",
        "    if total < 0:\n",
        "\n",
        "        total = 0\n",
        "\n",
        "    return total\"\"\"\n",
        "\n",
        "response_example = \"\"\"def calculate_total(prices, tax_rate, discount_rate, shipping_fee, gift_wrap_fee, membership_discount_rate):\n",
        "\n",
        "    def apply_percentage_discount(amount, percentage):\n",
        "\n",
        "        return amount * (1 - percentage / 100)\n",
        "\n",
        "    def calculate_shipping_fee(total):\n",
        "\n",
        "        return shipping_fee if total < 50 else shipping_fee / 2\n",
        "\n",
        "    def apply_tier_discount(total):\n",
        "\n",
        "        if total > 1000:\n",
        "\n",
        "            return total - 50\n",
        "\n",
        "        elif total > 500:\n",
        "\n",
        "            return total - 25\n",
        "\n",
        "        return total\n",
        "\n",
        "    subtotal = sum(prices)\n",
        "\n",
        "    subtotal = apply_percentage_discount(subtotal, membership_discount_rate)\n",
        "\n",
        "    subtotal = apply_percentage_discount(subtotal, discount_rate)\n",
        "\n",
        "\n",
        "\n",
        "    total = subtotal * (1 + tax_rate / 100)\n",
        "\n",
        "    total += calculate_shipping_fee(total)\n",
        "\n",
        "    total += gift_wrap_fee * len(prices)\n",
        "\n",
        "\n",
        "\n",
        "    total = apply_tier_discount(total)\n",
        "\n",
        "    total = max(0, round(total, 2))\n",
        "\n",
        "\n",
        "\n",
        "    return total\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "task = \"refactoring complex code\"\n",
        "\n",
        "prompt_example = \"\"\"\n",
        "\n",
        "You are an AI assistant that classifies a candidate's suitability for multiple job openings based on their CV. Your input will include:\n",
        "- The candidate's CV, delimited by #### characters \n",
        "- One or more job IDs, each delimited by <> characters\n",
        "- The corresponding job description for each job ID, delimited by ---- characters\n",
        "\n",
        "For each job ID provided, analyze the candidate's CV against the job description and requirements. Classify the candidate's suitability into one of five categories:\n",
        "- Highly Suitable \n",
        "- Moderately Suitable\n",
        "- Potentially Suitable\n",
        "- Marginally Suitable\n",
        "- Not Suitable\n",
        "\n",
        "In addition to the classification, provide a brief explanation for why you chose that suitability level, considering factors like:\n",
        "- The candidate's years of relevant experience \n",
        "- The match between the candidate's skills and qualifications and the job requirements\n",
        "- Any transferable skills from related industries\n",
        "- Gaps in required or preferred qualifications\n",
        "\n",
        "Generate your output as a list of JSON objects, with each object containing three keys:\n",
        "- id: The job ID, corresponding to the ones delimited by <> characters. Do not include the <> characters.\n",
        "- suitability: The classified suitability level\n",
        "- explanation: The brief explanation for the classification\n",
        "\n",
        "Example input 1:\n",
        "####\n",
        "John Doe\n",
        "Software Engineer\n",
        "5+ years experience in full-stack web development\n",
        "Proficient in JavaScript, Python, React, Node.js\n",
        "B.S. in Computer Science\n",
        "####\n",
        "<ID:21167>\n",
        "----\n",
        "Senior Frontend Engineer\n",
        "- 5+ years frontend development experience \n",
        "- Expert in React, Redux, TypeScript\n",
        "- Experience with unit testing\n",
        "----\n",
        "<ID:21239>\n",
        "----\n",
        "Data Scientist\n",
        "- Advanced degree in quantitative field\n",
        "- 3+ years experience in data analysis and modeling\n",
        "- Proficiency in R, SQL, data visualization tools\n",
        "----\n",
        "\n",
        "Example output 1:\n",
        "[\n",
        "  {\n",
        "    \"id\": \"21167\",\n",
        "    \"suitability\": \"Moderately Suitable\",\n",
        "    \"explanation\": \"The candidate has 5+ years of relevant web development experience and proficiency in React, but lacks mentioned expertise in Redux or TypeScript.\"\n",
        "  },\n",
        "  {\n",
        "    \"id\": \"21239\",\n",
        "    \"suitability\": \"Not Suitable\",\n",
        "    \"explanation\": \"The candidate lacks an advanced degree and experience in data science. Their skills are not transferable to this role.\"\n",
        "  }\n",
        "]\n",
        "\n",
        "Example input 2:\n",
        "\"\n",
        "####\n",
        "Jane Smith \n",
        "Marketing Manager\n",
        "7 years of experience in digital marketing\n",
        "Expertise in content strategy, SEO, social media, email campaigns\n",
        "Proven track record of increasing web traffic and conversion rates\n",
        "B.A. in Communication \n",
        "####\n",
        "<ID:21301>\n",
        "----\n",
        "Digital Marketing Specialist \n",
        "- 3+ years experience in digital marketing\n",
        "- Knowledge of SEO, SEM, social media, email marketing \n",
        "- Experience with Google Analytics, AdWords\n",
        "- Strong writing and communication skills\n",
        "----\n",
        "<ID:21354>\n",
        "----\n",
        "Product Marketing Manager\n",
        "- 5+ years in product marketing \n",
        "- Experience developing go-to-market strategies\n",
        "- Collaborates with product, sales, PR teams\n",
        "- Analyzes market trends and customer needs\n",
        "----\n",
        "\"\n",
        "\n",
        "Example output 2:\n",
        "\"\n",
        "[\n",
        "  {\n",
        "    \"id\": \"21301\", \n",
        "    \"suitability\": \"Highly Suitable\",\n",
        "    \"explanation\": \"The candidate has 7 years of directly relevant digital marketing experience and expertise in all the required areas like SEO, social media, and email marketing.\"\n",
        "  },\n",
        "  {\n",
        "    \"id\": \"21354\",\n",
        "    \"suitability\": \"Potentially Suitable\", \n",
        "    \"explanation\": \"While the candidate has extensive marketing experience, it's unclear if they have specific experience in product marketing, go-to-market strategies, and cross-functional collaboration. They may have transferable skills but lack some preferred qualifications.\"\n",
        "  }\n",
        "]\n",
        "\"\n",
        "\n",
        "Example input 3: \n",
        "\"\n",
        "####\n",
        "Michael Johnson\n",
        "Sales Associate \n",
        "2 years retail sales experience \n",
        "Consistently exceeded sales quotas by 20%+\n",
        "Strong interpersonal and customer service skills\n",
        "Pursuing B.S. in Business Administration \n",
        "####\n",
        "<ID:21402>\n",
        "----\n",
        "Account Executive \n",
        "- 5+ years B2B sales experience\n",
        "- Proven track record of growing accounts\n",
        "- Excellent presentation and negotiation skills\n",
        "- Knowledge of CRM systems like Salesforce\n",
        "----\n",
        "<ID:21458>\n",
        "----\n",
        "Retail Store Manager\n",
        "- 3+ years retail management experience \n",
        "- Track record of increasing store sales\n",
        "- Coaches and mentors sales associates\n",
        "- Ensures excellent customer experience \n",
        "----\n",
        "\"\n",
        "\n",
        "Example output 3:\n",
        "\"\n",
        "[\n",
        "  {\n",
        "    \"id\": \"21402\",\n",
        "    \"suitability\": \"Not Suitable\",\n",
        "    \"explanation\": \"The candidate only has 2 years of retail sales experience, lacking the 5+ years of B2B sales experience required. Their skills are not directly transferable to this Account Executive role.\"\n",
        "  },\n",
        "  {\n",
        "    \"id\": \"21458\", \n",
        "    \"suitability\": \"Moderately Suitable\",\n",
        "    \"explanation\": \"The candidate has 2 years of relevant retail sales experience and has demonstrated the ability to exceed sales goals. However, they lack the preferred 3+ years of retail management experience and leadership skills.\"\n",
        "  }\n",
        "]\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "response_example = \"\"\"\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMO3cJzWA-O0"
      },
      "source": [
        "### Now, let's run this system and get our new prompt! At the end, you'll see a new file pop up in the directory that contains everything you'll need to reduce your costs while keeping quality high w/ Haiku!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-Bn0rupAJqb"
      },
      "outputs": [],
      "source": [
        "result = run_haiku_conversion_process(task, prompt_example, response_example)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
